{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications import vgg16\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "#output = keras.layers.Dense(12, activation='softmax')(model.layers[-2].output)\n",
    "#resnet_model = keras.models.Model(model.inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pranjalgupta/Documents/Domain Adaption 2020/train\n"
     ]
    }
   ],
   "source": [
    "cd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "target_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    pil_image = keras.preprocessing.image.load_img(img, target_size=(224,224))\n",
    "    np_image = keras.preprocessing.image.img_to_array(pil_image)\n",
    "    #final_img = np.expand_dims(np_image,axis=0)\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = open('image_list.txt','r')\n",
    "n = 0\n",
    "p = 0\n",
    "for i in img_paths.readlines():\n",
    "    a = i.split()\n",
    "    if a[1] == str(p):\n",
    "        if n<200:\n",
    "            input_data.append(preprocess_image(a[0]))\n",
    "            target = np.array(p).reshape(-1)\n",
    "            onehot = np.eye(12)[target]\n",
    "            target_data.append(onehot)\n",
    "            n = n+1\n",
    "        else:\n",
    "            p = p+1\n",
    "            n = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 224, 224, 3)\n",
      "(2400, 1, 12)\n"
     ]
    }
   ],
   "source": [
    "np_input_data = np.array(input_data)\n",
    "np_target_data = np.array(target_data)\n",
    "print(np_input_data.shape)\n",
    "print(np_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_target_data.resize(2400,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 224, 224, 3)\n",
      "(2400, 12)\n"
     ]
    }
   ],
   "source": [
    "print(np_input_data.shape)\n",
    "print(np_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_input = vgg16.preprocess_input(np_input_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_pred_train = model.predict(processed_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 25088)\n"
     ]
    }
   ],
   "source": [
    "mid_pred = np.reshape(mid_pred_train, (2400,7*7*512))\n",
    "print(mid_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val_data = []\n",
    "target_val_data = []\n",
    "img_validation_paths = open('image_list.txt','r')\n",
    "n = 0\n",
    "p = 0\n",
    "for i in img_validation_paths.readlines():\n",
    "    a = i.split()\n",
    "    if a[1] == str(p):\n",
    "        if n<200:\n",
    "            input_val_data.append(preprocess_image(a[0]))\n",
    "            target = np.array(p).reshape(-1)\n",
    "            onehot = np.eye(12)[target]\n",
    "            target_val_data.append(onehot)\n",
    "            n = n+1\n",
    "        else:\n",
    "            p = p+1\n",
    "            n = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 224, 224, 3)\n",
      "(2400, 12)\n"
     ]
    }
   ],
   "source": [
    "np_input_val_data = np.array(input_val_data)\n",
    "np_target_val_data = np.array(target_val_data)\n",
    "np_target_val_data = np.reshape(np_target_val_data, (2400,12))\n",
    "print(np_input_val_data.shape)\n",
    "print(np_target_val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_val_input = vgg16.preprocess_input(np_input_val_data.copy())\n",
    "mid_pred_val = model.predict(proc_val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_pred_3 = np.reshape(mid_pred_val,(2400,7*7*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 6,425,868\n",
      "Trainable params: 6,425,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#classifier model on top of the trained model. \n",
    "vgg_model = keras.models.Sequential()\n",
    "vgg_model.add(keras.layers.Dense(256, activation='relu', input_dim=7 * 7 * 512))\n",
    "vgg_model.add(keras.layers.Dropout(0.5))\n",
    "vgg_model.add(keras.layers.Dense(12, activation='softmax'))\n",
    "\n",
    "vgg_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 3.0272 - accuracy: 0.8808\n",
      "Epoch 2/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.4312 - accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2030 - accuracy: 0.9792\n",
      "Epoch 4/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.1238 - accuracy: 0.9867\n",
      "Epoch 5/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2588 - accuracy: 0.9808\n",
      "Epoch 6/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2318 - accuracy: 0.9817\n",
      "Epoch 7/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.3462 - accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2371 - accuracy: 0.9858\n",
      "Epoch 9/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.4590 - accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.1634 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14afe4fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.fit(mid_pred, np_target_data, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save('vgg_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 1s 250us/step\n"
     ]
    }
   ],
   "source": [
    "train_result = vgg_model.evaluate(mid_pred, np_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 154us/step\n"
     ]
    }
   ],
   "source": [
    "val_result = vgg_model.evaluate(mid_pred_3, np_target_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tstinput(img):\n",
    "    tst_image = keras.preprocessing.image.load_img(img, target_size=(224,224))\n",
    "    tstnp_image = keras.preprocessing.image.img_to_array(tst_image)\n",
    "    s = np.expand_dims(tstnp_image, axis=0)\n",
    "    s = vgg16.preprocess_input(s.copy()) \n",
    "    f = model.predict(s)\n",
    "    f = np.reshape(f, (1,7*7*512))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "image_path = 'person/person_1203954.jpg'\n",
    "pred = vgg_model.predict(preprocess_tstinput(image_path))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (synthetic image) - 16.67\n",
      "Validation (real image) Accuracy - 11.08\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy (synthetic image) - {:.2f}'.format(train_result[1]*100))\n",
    "#print('Test Accuracy (synthetic image) - {:.2f}'.format(tst_result[1]*100))\n",
    "print('Validation (real image) Accuracy - {:.2f}'.format(val_result[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Domain Adaption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import random\\ndef create_pairs():\\n    pairs = []\\n    labels = []\\n    for i in range(12):\\n        for j in range(200):\\n            pairs = pairs+ [[np_input_data[(200*i)+j],np_input_val_data[(200*i)+j]]]\\n            x = random.randrange(1,12)\\n            i_n = (i+x)%12\\n            pairs = pairs + [[np_input_data[(200*i)+j], np_input_val_data[(200*i_n)+j]]]\\n            labels = labels + [1,0]\\n    return np.array(pairs),np.array(labels)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import random\n",
    "def create_pairs():\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for i in range(12):\n",
    "        for j in range(200):\n",
    "            pairs = pairs+ [[np_input_data[(200*i)+j],np_input_val_data[(200*i)+j]]]\n",
    "            x = random.randrange(1,12)\n",
    "            i_n = (i+x)%12\n",
    "            pairs = pairs + [[np_input_data[(200*i)+j], np_input_val_data[(200*i_n)+j]]]\n",
    "            labels = labels + [1,0]\n",
    "    return np.array(pairs),np.array(labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def create_pairs():\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for i in range(12):\n",
    "        for j in range(200):\n",
    "            pairs = pairs+ [[mid_pred[(200*i)+j],mid_pred_3[(200*i)+j]]]\n",
    "            x = random.randrange(1,12)\n",
    "            i_n = (i+x)%12\n",
    "            pairs = pairs + [[mid_pred[(200*i)+j], mid_pred_3[(200*i_n)+j]]]\n",
    "            labels = labels + [1,0]\n",
    "    return np.array(pairs),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs, train_labels =  create_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def basnet_out(input_dataset):\n",
    "    processed_input_dataset = keras.layers.Lambda(lambda x:vgg16.preprocess_input(x))(input_dataset)\n",
    "    middle_prediction = model(processed_input_dataset)\n",
    "    middle_prediction = keras.layers.Lambda(lambda x:tf.reshape(x, [-1, 7*7*512]))(middle_prediction)\n",
    "    encoding_dataset = vgg_model(middle_prediction)    \n",
    "    return encoding_dataset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basnet_out(input_dataset):\n",
    "    encoding_dataset = vgg_model(input_dataset)    \n",
    "    return encoding_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape = (25088,))\n",
    "input_b = keras.layers.Input(shape = (25088,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_a = basnet_out(input_a)\n",
    "processed_b = basnet_out(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = keras.layers.Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_model = keras.models.Model([input_a,input_b],distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_model.compile(optimizer = keras.optimizers.RMSprop(), loss = contrastive_loss, metrics = [accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4800/4800 [==============================] - 11s 2ms/step - loss: 0.5638 - accuracy: 0.5277\n",
      "Epoch 2/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5378 - accuracy: 0.5202\n",
      "Epoch 3/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5579 - accuracy: 0.5240\n",
      "Epoch 4/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5748 - accuracy: 0.5454\n",
      "Epoch 5/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5900 - accuracy: 0.5565\n",
      "Epoch 6/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5775 - accuracy: 0.5638\n",
      "Epoch 7/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5903 - accuracy: 0.5550\n",
      "Epoch 8/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5487 - accuracy: 0.5969\n",
      "Epoch 9/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.5291 - accuracy: 0.6083\n",
      "Epoch 10/10\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4799 - accuracy: 0.6431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14e97ca50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_model.fit([train_pairs[:,0,:], train_pairs[:,1,:]], train_labels , epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_model.save('final_da_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
